{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook, we will perform sentiment analysis on a dataset containing tweets on US airlines during 2015. We will first explore the dataset, do so some cleaning and feature selection, and then run a few machine learning algortihms to predict the sentiment of a particular tweet using NLP methods such as Term Frequency-Inverse Document Frequency (TF-IDF) which convert strings into numerical vectors for analysis.\n",
    "\n",
    "#### Workflow:\n",
    "\n",
    "1. Load the dataset into a dataframe\n",
    "2. Explore the dataframe\n",
    "3. Remove unnecessary columns\n",
    "4. Remove all punctuation from the text column\n",
    "5. Convert the text column into TF-IDF feature vectors\n",
    "6. Use classification algorithms to predict the sentiment using K-Fold Cross validation with a grid search on a few relevant hyperparameters. The classification algortihms we will be using are Logistic Regression, Multinomial Naive Bayes, and Support Vector Machines\n",
    "7. Compare the accuracies of the three classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the required libraries and fuctions\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#render charts inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the .csv dataset into a dataframe. The .csv file is actually encoded in ISO-8859-1\n",
    "df = pd.read_csv('Airline-Sentiment-2-w-AA.csv', encoding = 'ISO-8859-1') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment:confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason:confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>681448150</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 5:24</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/15 11:35</td>\n",
       "      <td>5.703060e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>681448153</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 1:53</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/15 11:15</td>\n",
       "      <td>5.703010e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>681448156</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 10:01</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/15 11:15</td>\n",
       "      <td>5.703010e+17</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>681448158</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 3:05</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/15 11:15</td>\n",
       "      <td>5.703010e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>681448159</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 5:50</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/15 11:14</td>\n",
       "      <td>5.703010e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
       "0  681448150    False   finalized                   3      2/25/15 5:24   \n",
       "1  681448153    False   finalized                   3      2/25/15 1:53   \n",
       "2  681448156    False   finalized                   3     2/25/15 10:01   \n",
       "3  681448158    False   finalized                   3      2/25/15 3:05   \n",
       "4  681448159    False   finalized                   3      2/25/15 5:50   \n",
       "\n",
       "  airline_sentiment  airline_sentiment:confidence negativereason  \\\n",
       "0           neutral                        1.0000            NaN   \n",
       "1          positive                        0.3486            NaN   \n",
       "2           neutral                        0.6837            NaN   \n",
       "3          negative                        1.0000     Bad Flight   \n",
       "4          negative                        1.0000     Can't Tell   \n",
       "\n",
       "   negativereason:confidence         airline airline_sentiment_gold  \\\n",
       "0                        NaN  Virgin America                    NaN   \n",
       "1                     0.0000  Virgin America                    NaN   \n",
       "2                        NaN  Virgin America                    NaN   \n",
       "3                     0.7033  Virgin America                    NaN   \n",
       "4                     1.0000  Virgin America                    NaN   \n",
       "\n",
       "         name negativereason_gold  retweet_count  \\\n",
       "0     cairdin                 NaN              0   \n",
       "1    jnardino                 NaN              0   \n",
       "2  yvonnalynn                 NaN              0   \n",
       "3    jnardino                 NaN              0   \n",
       "4    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "   tweet_created      tweet_id tweet_location               user_timezone  \n",
       "0  2/24/15 11:35  5.703060e+17            NaN  Eastern Time (US & Canada)  \n",
       "1  2/24/15 11:15  5.703010e+17            NaN  Pacific Time (US & Canada)  \n",
       "2  2/24/15 11:15  5.703010e+17      Lets Play  Central Time (US & Canada)  \n",
       "3  2/24/15 11:15  5.703010e+17            NaN  Pacific Time (US & Canada)  \n",
       "4  2/24/15 11:14  5.703010e+17            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14640 entries, 0 to 14639\n",
      "Data columns (total 20 columns):\n",
      "_unit_id                        14640 non-null int64\n",
      "_golden                         14640 non-null bool\n",
      "_unit_state                     14640 non-null object\n",
      "_trusted_judgments              14640 non-null int64\n",
      "_last_judgment_at               14584 non-null object\n",
      "airline_sentiment               14640 non-null object\n",
      "airline_sentiment:confidence    14640 non-null float64\n",
      "negativereason                  9178 non-null object\n",
      "negativereason:confidence       10522 non-null float64\n",
      "airline                         14640 non-null object\n",
      "airline_sentiment_gold          40 non-null object\n",
      "name                            14640 non-null object\n",
      "negativereason_gold             32 non-null object\n",
      "retweet_count                   14640 non-null int64\n",
      "text                            14640 non-null object\n",
      "tweet_coord                     1019 non-null object\n",
      "tweet_created                   14640 non-null object\n",
      "tweet_id                        14640 non-null float64\n",
      "tweet_location                  9907 non-null object\n",
      "user_timezone                   9820 non-null object\n",
      "dtypes: bool(1), float64(3), int64(3), object(13)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reason</th>\n",
       "      <th># of tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>2910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Late Flight</td>\n",
       "      <td>1665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cancelled Flight</td>\n",
       "      <td>847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lost Luggage</td>\n",
       "      <td>724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Flight Booking Problems</td>\n",
       "      <td>529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Flight Attendant Complaints</td>\n",
       "      <td>481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>longlines</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Damaged Luggage</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Reason  # of tweets\n",
       "3       Customer Service Issue         2910\n",
       "7                  Late Flight         1665\n",
       "1                   Can't Tell         1190\n",
       "2             Cancelled Flight          847\n",
       "8                 Lost Luggage          724\n",
       "0                   Bad Flight          580\n",
       "6      Flight Booking Problems          529\n",
       "5  Flight Attendant Complaints          481\n",
       "9                    longlines          178\n",
       "4              Damaged Luggage           74"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#What are the the reasons for the negative tweets?\n",
    "\n",
    "negative_tweets = df[['airline', 'negativereason']]\n",
    "df_negative = negative_tweets.groupby('negativereason', as_index=False).count().sort_values(by = 'airline', ascending = False)\n",
    "df_negative.columns = ['Reason', '# of tweets']\n",
    "df_negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like the biggest reason by far for negative tweets is due to poor customer service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all unnecessary columns for our analysis. We only need 'airline_sentiment', 'airline_sentiment:confidence','airline', and 'text' columns\n",
    "df = df[['airline_sentiment', 'airline_sentiment:confidence','airline', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment:confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment  airline_sentiment:confidence         airline  \\\n",
       "0           neutral                        1.0000  Virgin America   \n",
       "1          positive                        0.3486  Virgin America   \n",
       "2           neutral                        0.6837  Virgin America   \n",
       "3          negative                        1.0000  Virgin America   \n",
       "4          negative                        1.0000  Virgin America   \n",
       "\n",
       "                                                text  \n",
       "0                @VirginAmerica What @dhepburn said.  \n",
       "1  @VirginAmerica plus you've added commercials t...  \n",
       "2  @VirginAmerica I didn't today... Must mean I n...  \n",
       "3  @VirginAmerica it's really aggressive to blast...  \n",
       "4  @VirginAmerica and it's a really big bad thing...  "
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for our analysis we will only focus on positive and negative sentiments\n",
    "df = df[(df['airline_sentiment'] == 'positive')|(df['airline_sentiment'] =='negative')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment:confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>positive</td>\n",
       "      <td>0.6745</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>positive</td>\n",
       "      <td>0.6559</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@virginamerica Well, I didn'tÛ_but NOW I DO! :-D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica it was amazing, and arrived an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica I &amp;lt;3 pretty graphics. so muc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica This is such a great deal! Alre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>positive</td>\n",
       "      <td>0.6451</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica @virginmedia I'm flying your #f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   airline_sentiment  airline_sentiment:confidence         airline  \\\n",
       "1           positive                        0.3486  Virgin America   \n",
       "3           negative                        1.0000  Virgin America   \n",
       "4           negative                        1.0000  Virgin America   \n",
       "5           negative                        1.0000  Virgin America   \n",
       "6           positive                        0.6745  Virgin America   \n",
       "8           positive                        0.6559  Virgin America   \n",
       "9           positive                        1.0000  Virgin America   \n",
       "11          positive                        1.0000  Virgin America   \n",
       "12          positive                        1.0000  Virgin America   \n",
       "13          positive                        0.6451  Virgin America   \n",
       "\n",
       "                                                 text  \n",
       "1   @VirginAmerica plus you've added commercials t...  \n",
       "3   @VirginAmerica it's really aggressive to blast...  \n",
       "4   @VirginAmerica and it's a really big bad thing...  \n",
       "5   @VirginAmerica seriously would pay $30 a fligh...  \n",
       "6   @VirginAmerica yes, nearly every time I fly VX...  \n",
       "8   @virginamerica Well, I didn'tÛ_but NOW I DO! :-D  \n",
       "9   @VirginAmerica it was amazing, and arrived an ...  \n",
       "11  @VirginAmerica I &lt;3 pretty graphics. so muc...  \n",
       "12  @VirginAmerica This is such a great deal! Alre...  \n",
       "13  @VirginAmerica @virginmedia I'm flying your #f...  "
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment:confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica it was amazing, and arrived an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica I &amp;lt;3 pretty graphics. so muc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   airline_sentiment  airline_sentiment:confidence         airline  \\\n",
       "3           negative                           1.0  Virgin America   \n",
       "4           negative                           1.0  Virgin America   \n",
       "5           negative                           1.0  Virgin America   \n",
       "9           positive                           1.0  Virgin America   \n",
       "11          positive                           1.0  Virgin America   \n",
       "\n",
       "                                                 text  \n",
       "3   @VirginAmerica it's really aggressive to blast...  \n",
       "4   @VirginAmerica and it's a really big bad thing...  \n",
       "5   @VirginAmerica seriously would pay $30 a fligh...  \n",
       "9   @VirginAmerica it was amazing, and arrived an ...  \n",
       "11  @VirginAmerica I &lt;3 pretty graphics. so muc...  "
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets just focus on sentiments which were outright positive or negative\n",
    "df = df[df['airline_sentiment:confidence']==1]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment:confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica it was amazing, and arrived an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica I &amp;lt;3 pretty graphics. so muc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment  airline_sentiment:confidence         airline  \\\n",
       "0          negative                           1.0  Virgin America   \n",
       "1          negative                           1.0  Virgin America   \n",
       "2          negative                           1.0  Virgin America   \n",
       "3          positive                           1.0  Virgin America   \n",
       "4          positive                           1.0  Virgin America   \n",
       "\n",
       "                                                text  \n",
       "0  @VirginAmerica it's really aggressive to blast...  \n",
       "1  @VirginAmerica and it's a really big bad thing...  \n",
       "2  @VirginAmerica seriously would pay $30 a fligh...  \n",
       "3  @VirginAmerica it was amazing, and arrived an ...  \n",
       "4  @VirginAmerica I &lt;3 pretty graphics. so muc...  "
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reset the indices of the dataframe to be in order from 0\n",
    "df = df.reset_index() \n",
    "df = df.drop(columns = ['index'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airline</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>United</th>\n",
       "      <td>2418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US Airways</th>\n",
       "      <td>2068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>American</th>\n",
       "      <td>1856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Southwest</th>\n",
       "      <td>1296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delta</th>\n",
       "      <td>1026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virgin America</th>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                airline_sentiment\n",
       "airline                          \n",
       "United                       2418\n",
       "US Airways                   2068\n",
       "American                     1856\n",
       "Southwest                    1296\n",
       "Delta                        1026\n",
       "Virgin America                233"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how many tweets were made for each airline\n",
    "df.groupby('airline').agg({'airline_sentiment':'count'}).sort_values(by = 'airline_sentiment', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like the three most tweeted airlines are United Airlines, US Airways, and American Airlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">airline_sentiment:confidence</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airline</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>American</th>\n",
       "      <td>1635.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>7.398190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delta</th>\n",
       "      <td>688.0</td>\n",
       "      <td>338.0</td>\n",
       "      <td>2.035503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Southwest</th>\n",
       "      <td>909.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>2.348837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US Airways</th>\n",
       "      <td>1901.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>11.383234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United</th>\n",
       "      <td>2120.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>7.114094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virgin America</th>\n",
       "      <td>129.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>1.240385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  airline_sentiment:confidence               ratio\n",
       "airline_sentiment                     negative positive           \n",
       "airline                                                           \n",
       "American                                1635.0    221.0   7.398190\n",
       "Delta                                    688.0    338.0   2.035503\n",
       "Southwest                                909.0    387.0   2.348837\n",
       "US Airways                              1901.0    167.0  11.383234\n",
       "United                                  2120.0    298.0   7.114094\n",
       "Virgin America                           129.0    104.0   1.240385"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#which airlines has the most number of negative tweets? We need to calculate the ratio of the negative to positive tweets to make an accurate assessment because if we just go by the number of negative tweets then the airline with the most tweets would be disadvantaged\n",
    "table = pd.pivot_table(df, index = ['airline'],columns = ['airline_sentiment'], aggfunc=np.sum)\n",
    "table['ratio'] = table.iloc[:,0]/table.iloc[:,1]\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like US Airways has the highest ratio of negative to positive tweets and is therefore the most negatively reviewed airline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment:confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica it was amazing, and arrived an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica I &amp;lt;3 pretty graphics. so muc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica This is such a great deal! Alre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica Thanks!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica So excited for my first cross c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica  I flew from NYC to SFO last we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>I _ü flying @VirginAmerica. ÷¼ü_ÙÔ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   airline_sentiment  airline_sentiment:confidence         airline  \\\n",
       "0                  0                           1.0  Virgin America   \n",
       "1                  0                           1.0  Virgin America   \n",
       "2                  0                           1.0  Virgin America   \n",
       "3                  1                           1.0  Virgin America   \n",
       "4                  1                           1.0  Virgin America   \n",
       "5                  1                           1.0  Virgin America   \n",
       "6                  1                           1.0  Virgin America   \n",
       "7                  1                           1.0  Virgin America   \n",
       "8                  0                           1.0  Virgin America   \n",
       "9                  1                           1.0  Virgin America   \n",
       "\n",
       "                                                text  \n",
       "0  @VirginAmerica it's really aggressive to blast...  \n",
       "1  @VirginAmerica and it's a really big bad thing...  \n",
       "2  @VirginAmerica seriously would pay $30 a fligh...  \n",
       "3  @VirginAmerica it was amazing, and arrived an ...  \n",
       "4  @VirginAmerica I &lt;3 pretty graphics. so muc...  \n",
       "5  @VirginAmerica This is such a great deal! Alre...  \n",
       "6                             @VirginAmerica Thanks!  \n",
       "7  @VirginAmerica So excited for my first cross c...  \n",
       "8  @VirginAmerica  I flew from NYC to SFO last we...  \n",
       "9         I _ü flying @VirginAmerica. ÷¼ü_ÙÔ  "
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For our analysis we need to convert the 'positive' and 'negative' values to numerical 1 and 0 values\n",
    "def sentiment_class(sentiment):\n",
    "    if sentiment == 'negative':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "df['airline_sentiment'] = df['airline_sentiment'].apply(sentiment_class)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the remaining unnecessary columns\n",
    "df = df.drop(['airline_sentiment:confidence', 'airline'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>virginamerica its really aggressive to blast o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>virginamerica and its a really big bad thing a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>virginamerica seriously would pay 30 a flight ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>virginamerica it was amazing and arrived an ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>virginamerica i lt3 pretty graphics so much be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>virginamerica this is such a great deal alread...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>virginamerica thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>virginamerica so excited for my first cross co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>virginamerica  i flew from nyc to sfo last wee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>i  flying virginamerica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   airline_sentiment                                               text\n",
       "0                  0  virginamerica its really aggressive to blast o...\n",
       "1                  0  virginamerica and its a really big bad thing a...\n",
       "2                  0  virginamerica seriously would pay 30 a flight ...\n",
       "3                  1  virginamerica it was amazing and arrived an ho...\n",
       "4                  1  virginamerica i lt3 pretty graphics so much be...\n",
       "5                  1  virginamerica this is such a great deal alread...\n",
       "6                  1                               virginamerica thanks\n",
       "7                  1  virginamerica so excited for my first cross co...\n",
       "8                  0  virginamerica  i flew from nyc to sfo last wee...\n",
       "9                  1                            i  flying virginamerica"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define a function to clean the target 'text' column by removing all punctuation, making it lowercase, and removing leading and trailing whitespaces\n",
    "import re\n",
    "\n",
    "def remove_punctuation(string):\n",
    "    return(re.sub('[^\\sa-zA-Z0-9]', '',string).lower()) #remove puntuation and make lowercase\n",
    "df['text'] = df['text'].apply(remove_punctuation)\n",
    "\n",
    "df['text'] = df['text'].str.strip() #remove leading and trailing whitespaces\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop and Evaluate Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to convert the text in the target 'text' column into numerical feature vectors. We can do this by utilizing the TF-IDF Vectorizer. TF-IDF Vectorizes assigns a TF-IDF score to each word based on how often that word occurs in each tweet and how oftern it occurs in other documents. The score is boosted if the work occurs several times in a tweet but is also subsequently penalized if it occurs in several other documents. The logic is that a word that occurs in several other documents does not help much in making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_val_predict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "lr = LogisticRegression() # initiate a logistic regression model\n",
    "\n",
    "#identify the features and labels of the training set\n",
    "train = df['text']\n",
    "labels = df['airline_sentiment']\n",
    "\n",
    "\n",
    "tf_idf_vec = TfidfVectorizer() #initiate the TF-IDF Vectorizer\n",
    "tf_idf = tf_idf_vec.fit_transform(train) #transform the 'text' column into TF-IDF feature vectors\n",
    "cv_scores = cross_val_score(lr, tf_idf, labels, cv = 5) #run a 5-fold cross validation of the logistic regression model on the TF-IDF feature vectors for predicting sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9149155882297213"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate the mean accuracy score\n",
    "mean_score = np.mean(cv_scores)\n",
    "mean_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A score of 91.5% is very good! Lets see what tf-idf feature vectors look like by converting the TF-IDF feature matrix into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8897, 11759)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0162431184663</th>\n",
       "      <th>0214</th>\n",
       "      <th>021mbps</th>\n",
       "      <th>0223</th>\n",
       "      <th>02282015</th>\n",
       "      <th>03</th>\n",
       "      <th>0303</th>\n",
       "      <th>03032015</th>\n",
       "      <th>0316</th>\n",
       "      <th>0372389047497</th>\n",
       "      <th>...</th>\n",
       "      <th>zip</th>\n",
       "      <th>zippers</th>\n",
       "      <th>zkatcher</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zrh</th>\n",
       "      <th>zukes</th>\n",
       "      <th>zurich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 11759 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0162431184663  0214  021mbps  0223  02282015   03  0303  03032015  0316  \\\n",
       "0            0.0   0.0      0.0   0.0       0.0  0.0   0.0       0.0   0.0   \n",
       "1            0.0   0.0      0.0   0.0       0.0  0.0   0.0       0.0   0.0   \n",
       "2            0.0   0.0      0.0   0.0       0.0  0.0   0.0       0.0   0.0   \n",
       "3            0.0   0.0      0.0   0.0       0.0  0.0   0.0       0.0   0.0   \n",
       "4            0.0   0.0      0.0   0.0       0.0  0.0   0.0       0.0   0.0   \n",
       "\n",
       "   0372389047497   ...    zip  zippers  zkatcher  zombie  zone  zones  zoom  \\\n",
       "0            0.0   ...    0.0      0.0       0.0     0.0   0.0    0.0   0.0   \n",
       "1            0.0   ...    0.0      0.0       0.0     0.0   0.0    0.0   0.0   \n",
       "2            0.0   ...    0.0      0.0       0.0     0.0   0.0    0.0   0.0   \n",
       "3            0.0   ...    0.0      0.0       0.0     0.0   0.0    0.0   0.0   \n",
       "4            0.0   ...    0.0      0.0       0.0     0.0   0.0    0.0   0.0   \n",
       "\n",
       "   zrh  zukes  zurich  \n",
       "0  0.0    0.0     0.0  \n",
       "1  0.0    0.0     0.0  \n",
       "2  0.0    0.0     0.0  \n",
       "3  0.0    0.0     0.0  \n",
       "4  0.0    0.0     0.0  \n",
       "\n",
       "[5 rows x 11759 columns]"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_df = pd.DataFrame(tf_idf.todense(),columns=tf_idf_vec.get_feature_names()) #convert the tf-idf matrix into a dataframe with the column names corresponding to the unique word tokens\n",
    "print(transformed_df.shape)\n",
    "transformed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Obtain predictions from the 5-fold cross validation and append it to the dataframe for a quick visual comparison\n",
    "cv_predictions = cross_val_predict(lr, tf_idf, labels, cv = 5)\n",
    "cv_predictions = pd.Series(cv_predictions)\n",
    "df['predicted_sentiment'] = cv_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>predicted_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7430</th>\n",
       "      <td>0</td>\n",
       "      <td>americanair 2284 four hours late flightrs and ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5992</th>\n",
       "      <td>0</td>\n",
       "      <td>usairways please help on hold 3 hours cant cha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5386</th>\n",
       "      <td>0</td>\n",
       "      <td>usairways forced sections 4 and 5 to check the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7868</th>\n",
       "      <td>0</td>\n",
       "      <td>americanair customer service is terriblebeen w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6827</th>\n",
       "      <td>0</td>\n",
       "      <td>usairways already called no other options flig...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6567</th>\n",
       "      <td>0</td>\n",
       "      <td>usairways they had to turn the seat cushions o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8132</th>\n",
       "      <td>0</td>\n",
       "      <td>americanair your customer service is inferior ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>0</td>\n",
       "      <td>united once again you guys didnt let me down a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5956</th>\n",
       "      <td>0</td>\n",
       "      <td>usairways are you going to do anything to help...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6622</th>\n",
       "      <td>0</td>\n",
       "      <td>usairways delays to the max</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      airline_sentiment                                               text  \\\n",
       "7430                  0  americanair 2284 four hours late flightrs and ...   \n",
       "5992                  0  usairways please help on hold 3 hours cant cha...   \n",
       "5386                  0  usairways forced sections 4 and 5 to check the...   \n",
       "7868                  0  americanair customer service is terriblebeen w...   \n",
       "6827                  0  usairways already called no other options flig...   \n",
       "6567                  0  usairways they had to turn the seat cushions o...   \n",
       "8132                  0  americanair your customer service is inferior ...   \n",
       "1127                  0  united once again you guys didnt let me down a...   \n",
       "5956                  0  usairways are you going to do anything to help...   \n",
       "6622                  0                        usairways delays to the max   \n",
       "\n",
       "      predicted_sentiment  \n",
       "7430                    0  \n",
       "5992                    0  \n",
       "5386                    0  \n",
       "7868                    0  \n",
       "6827                    0  \n",
       "6567                    0  \n",
       "8132                    0  \n",
       "1127                    0  \n",
       "5956                    0  \n",
       "6622                    0  "
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10, random_state = 42) #obtain a random sample of 10 tweets for a quick visual check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good on this sample! Now, lets perform a grid-search with cross validation in order to determine if a unigram TF-IDF model provides better results than multigram TF-IDF models. Unigram means that a sentence is broken down into single word tokens while multigram means that a sentence is broken down into multiple word tokens. \n",
    "\n",
    "We will also create a pipeline that first performs TF-IDF vectorization and then logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('tf_idf_vec', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=..., penalty='l2', random_state=42, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid=[{'tf_idf_vec__ngram_range': [(1, 1), (1, 2), (1, 3)]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [{'tf_idf_vec__ngram_range':[(1,1),(1,2),(1,3)]}] #a parameter grid containing 1-gram, 2-gram, and 3-gram values for the ngram_range hyperparameter of the tf-idf vectorizer\n",
    "lr_tfidf = Pipeline([('tf_idf_vec', tf_idf_vec), ('lr', LogisticRegression(random_state = 42))]) #create the pipeline for tf-idf vectorization followed by logistic regression\n",
    "grid_search = GridSearchCV(lr_tfidf, param_grid, cv = 5, scoring = 'accuracy')\n",
    "grid_search.fit(train, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tf_idf_vec__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_) #print the hyperparameter which provided the highest mean accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9072721141957963 {'tf_idf_vec__ngram_range': (1, 1)}\n",
      "0.9046869731370125 {'tf_idf_vec__ngram_range': (1, 2)}\n",
      "0.9013150500168596 {'tf_idf_vec__ngram_range': (1, 3)}\n"
     ]
    }
   ],
   "source": [
    "#print the scores of all three hyperparameter values\n",
    "cvres = grid_search.cv_results_\n",
    "for score, params in zip(cvres['mean_test_score'], cvres['params']):\n",
    "    print(score, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it seems that a 1-gram model provides the highest mean accuracy score of 91%. Let's see how a multinomial naive bayes model performs using the same methodology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('tf_idf_vec', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=...        vocabulary=None)), ('multi_nb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid=[{'tf_idf_vec__ngram_range': [(1, 1), (1, 2), (1, 3)]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb_tfidf = Pipeline([('tf_idf_vec', tf_idf_vec), ('multi_nb', MultinomialNB())])\n",
    "grid_search = GridSearchCV(nb_tfidf, param_grid, cv = 5, scoring = 'accuracy')\n",
    "grid_search.fit(train, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tf_idf_vec__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8490502416544903 {'tf_idf_vec__ngram_range': (1, 1)}\n",
      "0.8443295492862762 {'tf_idf_vec__ngram_range': (1, 2)}\n",
      "0.8430931774755536 {'tf_idf_vec__ngram_range': (1, 3)}\n"
     ]
    }
   ],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for score, params in zip(cvres['mean_test_score'], cvres['params']):\n",
    "    print(score, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest naive bayes accuracy score is 85% which was again for the 1-gram model. But this accuracy score is less than the one obtained through logistic regression. Let's see how a Support Vector Machine (SVM) performs using the same methodology. Note that we will be training the model with three different learning rates 0.001,0.01, and 0.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('tf_idf_vec', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=...dom_state=42, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid=[{'tf_idf_vec__ngram_range': [(1, 1), (1, 2), (1, 3)], 'svm__alpha': [0.001, 0.01, 0.1]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "param_grid = [{'tf_idf_vec__ngram_range':[(1,1),(1,2),(1,3)], 'svm__alpha':[0.001,0.01,0.1]}] #use three different values for the learning rate hyperparameter - 0.001,0.01,and 0.1\n",
    "svm_tfidf = Pipeline([('tf_idf_vec', tf_idf_vec), ('svm', SGDClassifier(loss='hinge', penalty='l2', random_state=42, max_iter=5, tol = None))])\n",
    "grid_search = GridSearchCV(svm_tfidf, param_grid, cv = 5, scoring = 'accuracy')\n",
    "grid_search.fit(train, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__alpha': 0.001, 'tf_idf_vec__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8920984601551084 {'svm__alpha': 0.001, 'tf_idf_vec__ngram_range': (1, 1)}\n",
      "0.8834438574800495 {'svm__alpha': 0.001, 'tf_idf_vec__ngram_range': (1, 2)}\n",
      "0.8750140496796673 {'svm__alpha': 0.001, 'tf_idf_vec__ngram_range': (1, 3)}\n",
      "0.8312914465550185 {'svm__alpha': 0.01, 'tf_idf_vec__ngram_range': (1, 1)}\n",
      "0.8297178824322805 {'svm__alpha': 0.01, 'tf_idf_vec__ngram_range': (1, 2)}\n",
      "0.8297178824322805 {'svm__alpha': 0.01, 'tf_idf_vec__ngram_range': (1, 3)}\n",
      "0.8297178824322805 {'svm__alpha': 0.1, 'tf_idf_vec__ngram_range': (1, 1)}\n",
      "0.8297178824322805 {'svm__alpha': 0.1, 'tf_idf_vec__ngram_range': (1, 2)}\n",
      "0.8297178824322805 {'svm__alpha': 0.1, 'tf_idf_vec__ngram_range': (1, 3)}\n"
     ]
    }
   ],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for score, params in zip(cvres['mean_test_score'], cvres['params']):\n",
    "    print(score, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, it looks like the highest accuracy score for the SVM model is 89% with a learning rate of 0.001, utilizing unigram tokens. Therefore, for this particular problem, logistic regression was able to perform the best with the highest accuracy score of 91% and the SVM did better than Naive Bayes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
